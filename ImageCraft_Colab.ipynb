{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b16a242f595c4900b32158f3a7601d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d39d2c6eaad4318aa58a8c599574423",
              "IPY_MODEL_952591a5a5754a8c9024be44664e66c9",
              "IPY_MODEL_45c56936ac804dacbb0929a98d0b55da"
            ],
            "layout": "IPY_MODEL_08938eaef7e046a890deb289f937059a"
          }
        },
        "9d39d2c6eaad4318aa58a8c599574423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38c5665e4ce4ac9bb18872b4023c2f2",
            "placeholder": "​",
            "style": "IPY_MODEL_40cd38a2d2294487b760264ac55b5f96",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "952591a5a5754a8c9024be44664e66c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd99cd0486fd47678430884a55872372",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17f671a9538146758cba9c5d11ccd94b",
            "value": 26
          }
        },
        "45c56936ac804dacbb0929a98d0b55da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c66923f8a2947e38b3832b5c4a0ff34",
            "placeholder": "​",
            "style": "IPY_MODEL_e54c32f3d6074b63afe8a1e297ad325a",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.56kB/s]"
          }
        },
        "08938eaef7e046a890deb289f937059a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38c5665e4ce4ac9bb18872b4023c2f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40cd38a2d2294487b760264ac55b5f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd99cd0486fd47678430884a55872372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f671a9538146758cba9c5d11ccd94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c66923f8a2947e38b3832b5c4a0ff34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54c32f3d6074b63afe8a1e297ad325a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ded22e93b604258a2b96e2a11646bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64926a61fca04e438f388a476b490345",
              "IPY_MODEL_7d846111de834ef387dedf6a4d71f6d7",
              "IPY_MODEL_521530748da34f61884b68ab26e8c282"
            ],
            "layout": "IPY_MODEL_97f9f6a829e0418fa33d2516dfc3df78"
          }
        },
        "64926a61fca04e438f388a476b490345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d9d575622354a39b71c66ef3edf70c6",
            "placeholder": "​",
            "style": "IPY_MODEL_ba0e2a91372241c39a69690e32ca0df0",
            "value": "config.json: 100%"
          }
        },
        "7d846111de834ef387dedf6a4d71f6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f30605af0b64156b3986a9c6512d73f",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f1b4c19218545baa7759049e45ec3e3",
            "value": 665
          }
        },
        "521530748da34f61884b68ab26e8c282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_489ec015d8394036906b48a888a261b5",
            "placeholder": "​",
            "style": "IPY_MODEL_6adc1fa618624787ab5a2ab9942384ce",
            "value": " 665/665 [00:00&lt;00:00, 72.3kB/s]"
          }
        },
        "97f9f6a829e0418fa33d2516dfc3df78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9d575622354a39b71c66ef3edf70c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba0e2a91372241c39a69690e32ca0df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f30605af0b64156b3986a9c6512d73f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1b4c19218545baa7759049e45ec3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "489ec015d8394036906b48a888a261b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6adc1fa618624787ab5a2ab9942384ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3f1a25e4f8446f2a09be2d556f5dc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f437d90c504d4a8ca7a879967faab33f",
              "IPY_MODEL_cf1d6baa2f034737ad1f935744dd99fb",
              "IPY_MODEL_0a15690a4bd24c1f8a701fe2f5f746fe"
            ],
            "layout": "IPY_MODEL_c2012d7723bf4498906557d3a710478f"
          }
        },
        "f437d90c504d4a8ca7a879967faab33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37c4885451f489490514f7564662194",
            "placeholder": "​",
            "style": "IPY_MODEL_3be2af1c9c64461bbea2b342a89af209",
            "value": "vocab.json: 100%"
          }
        },
        "cf1d6baa2f034737ad1f935744dd99fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8550fa39b4c54e1a9c855d25e3ad6381",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68eb0f95264b40ad853500907636b766",
            "value": 1042301
          }
        },
        "0a15690a4bd24c1f8a701fe2f5f746fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a68b1d38e04440bafbd494418b5f49a",
            "placeholder": "​",
            "style": "IPY_MODEL_db0417f070b44e4b8d0016e7f7a1047f",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.38MB/s]"
          }
        },
        "c2012d7723bf4498906557d3a710478f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c37c4885451f489490514f7564662194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be2af1c9c64461bbea2b342a89af209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8550fa39b4c54e1a9c855d25e3ad6381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68eb0f95264b40ad853500907636b766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a68b1d38e04440bafbd494418b5f49a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db0417f070b44e4b8d0016e7f7a1047f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfb6fdd4257a4616b7be50cee096c3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d5793e0c31c4666a8f7a216f071cf8e",
              "IPY_MODEL_a1171e8c364d4f178468ec6e80904fc7",
              "IPY_MODEL_bec0a0051ec04cb5bc7683c2e1cfe8a6"
            ],
            "layout": "IPY_MODEL_0948ffca77784fddb523aee4cff3a344"
          }
        },
        "7d5793e0c31c4666a8f7a216f071cf8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15dd8404550f43b284bf9792621b4174",
            "placeholder": "​",
            "style": "IPY_MODEL_ea4b1c258ec1478589873ce52c025509",
            "value": "merges.txt: 100%"
          }
        },
        "a1171e8c364d4f178468ec6e80904fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffff980c6dcd4c9bac8f83de98ad554a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b75d0dc63334228b97fc42db475df37",
            "value": 456318
          }
        },
        "bec0a0051ec04cb5bc7683c2e1cfe8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9053cfe0de44dd98f3d457c00667234",
            "placeholder": "​",
            "style": "IPY_MODEL_9780bf95532f4333bf3e96a0b0dd5f30",
            "value": " 456k/456k [00:00&lt;00:00, 42.7MB/s]"
          }
        },
        "0948ffca77784fddb523aee4cff3a344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15dd8404550f43b284bf9792621b4174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea4b1c258ec1478589873ce52c025509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffff980c6dcd4c9bac8f83de98ad554a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b75d0dc63334228b97fc42db475df37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9053cfe0de44dd98f3d457c00667234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9780bf95532f4333bf3e96a0b0dd5f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76be7eb355e4405593a5e00ba54d155c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cad5df67fc0147d6876850be9e3a1791",
              "IPY_MODEL_c3895efcceef49ecbe44906f03b231b0",
              "IPY_MODEL_593f88b650eb48eb8af0dbe51ed66cff"
            ],
            "layout": "IPY_MODEL_be99d5ca86f74470a7a684267e967cf7"
          }
        },
        "cad5df67fc0147d6876850be9e3a1791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95817f3b074047d8a07fde98945c6bad",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a5bff435aa4c41b4c4cdfd5e72401f",
            "value": "tokenizer.json: 100%"
          }
        },
        "c3895efcceef49ecbe44906f03b231b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b93a5ea17b2a4f7e8021b78820fca13e",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fce7ac0b0db42459c446a1f99aafced",
            "value": 1355256
          }
        },
        "593f88b650eb48eb8af0dbe51ed66cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_759a1c95166048cf9d03115115dc96de",
            "placeholder": "​",
            "style": "IPY_MODEL_4764591e17194205b08c5baada26613a",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 64.2MB/s]"
          }
        },
        "be99d5ca86f74470a7a684267e967cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95817f3b074047d8a07fde98945c6bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a5bff435aa4c41b4c4cdfd5e72401f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b93a5ea17b2a4f7e8021b78820fca13e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fce7ac0b0db42459c446a1f99aafced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "759a1c95166048cf9d03115115dc96de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4764591e17194205b08c5baada26613a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34571f245ed44416a0982fab9628fd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fc19166924c4381b220c4a141cb99e1",
              "IPY_MODEL_1395630b2ef74cd2827121be0e04e87c",
              "IPY_MODEL_84be95abe875418cae409d14b61cf212"
            ],
            "layout": "IPY_MODEL_ed43824f76dd4fdf8c7ce1564bf78911"
          }
        },
        "1fc19166924c4381b220c4a141cb99e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6384dd00bc411f83a1cd3e7a6ad37d",
            "placeholder": "​",
            "style": "IPY_MODEL_9e441275178942a9bb6cedc1df39dcc4",
            "value": "model.safetensors: 100%"
          }
        },
        "1395630b2ef74cd2827121be0e04e87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d77f568500441d8783616d2359c0f5",
            "max": 22883348,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02fab976378e4931b4b9899a0c026cba",
            "value": 22883348
          }
        },
        "84be95abe875418cae409d14b61cf212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0069bb6c193a4e7380fedb3c64656e3b",
            "placeholder": "​",
            "style": "IPY_MODEL_df768885337142af8cd36f2e2cdb30d9",
            "value": " 22.9M/22.9M [00:00&lt;00:00, 217MB/s]"
          }
        },
        "ed43824f76dd4fdf8c7ce1564bf78911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6384dd00bc411f83a1cd3e7a6ad37d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e441275178942a9bb6cedc1df39dcc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d77f568500441d8783616d2359c0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02fab976378e4931b4b9899a0c026cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0069bb6c193a4e7380fedb3c64656e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df768885337142af8cd36f2e2cdb30d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y git-core ffmpeg espeak-ng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U88SqLpYU3W9",
        "outputId": "38e714cd-34fd-4738-9179-a6347ecff0a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'git' instead of 'git-core'\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak-ng espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,526 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpcaudio0 amd64 1.1-6build2 [8,956 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 espeak-ng-data amd64 1.50+dfsg-10ubuntu0.1 [3,956 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libespeak-ng1 amd64 1.50+dfsg-10ubuntu0.1 [207 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 espeak-ng amd64 1.50+dfsg-10ubuntu0.1 [343 kB]\n",
            "Fetched 4,526 kB in 2s (1,898 kB/s)\n",
            "Selecting previously unselected package libpcaudio0:amd64.\n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcaudio0_1.1-6build2_amd64.deb ...\n",
            "Unpacking libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Selecting previously unselected package espeak-ng-data:amd64.\n",
            "Preparing to unpack .../espeak-ng-data_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package libespeak-ng1:amd64.\n",
            "Preparing to unpack .../libespeak-ng1_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package espeak-ng.\n",
            "Preparing to unpack .../espeak-ng_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Setting up espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KOh3buVyACvk",
        "outputId": "d2712344-6428-459f-9604-e69f3ffc80e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.5)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Collecting timm\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting phonemizer\n",
            "  Downloading phonemizer-3.3.0-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from phonemizer) (1.4.2)\n",
            "Collecting segments (from phonemizer)\n",
            "  Downloading segments-2.2.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.10/dist-packages (from phonemizer) (24.2.0)\n",
            "Collecting dlinfo (from phonemizer)\n",
            "  Downloading dlinfo-1.2.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.114.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Collecting clldutils>=1.7.3 (from segments->phonemizer)\n",
            "  Downloading clldutils-3.22.2-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting csvw>=1.5.6 (from segments->phonemizer)\n",
            "  Downloading csvw-3.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (0.9.0)\n",
            "Collecting colorlog (from clldutils>=1.7.3->segments->phonemizer)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting bibtexparser>=2.0.0b4 (from clldutils>=1.7.3->segments->phonemizer)\n",
            "  Downloading bibtexparser-2.0.0b7-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pylatexenc (from clldutils>=1.7.3->segments->phonemizer)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (3.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer) (4.9.4)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.16.0)\n",
            "Collecting colorama (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting isodate (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.23.0)\n",
            "Collecting language-tags (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading language_tags-1.2.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting rdflib (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting rfc3986<2 (from csvw>=1.5.6->segments->phonemizer)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.20.0)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phonemizer-3.3.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.114.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dlinfo-1.2.1-py3-none-any.whl (3.6 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading segments-2.2.1-py2.py3-none-any.whl (15 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clldutils-3.22.2-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading csvw-3.3.1-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bibtexparser-2.0.0b7-py3-none-any.whl (38 kB)\n",
            "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading language_tags-1.2.0-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=669390c6a3d177187a02ac0c182d5e434eaa46b497d629bd642de2aae113d7d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: rfc3986, pylatexenc, pydub, language-tags, dlinfo, xxhash, websockets, tomlkit, semantic-version, ruff, python-multipart, pyarrow, orjson, isodate, h11, ffmpy, dill, colorlog, colorama, bibtexparser, aiofiles, uvicorn, starlette, rdflib, multiprocess, httpcore, clldutils, httpx, fastapi, timm, gradio-client, csvw, segments, gradio, datasets, phonemizer\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.2\n",
            "    Uninstalling tomlkit-0.13.2:\n",
            "      Successfully uninstalled tomlkit-0.13.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 bibtexparser-2.0.0b7 clldutils-3.22.2 colorama-0.4.6 colorlog-6.8.2 csvw-3.3.1 datasets-3.0.0 dill-0.3.8 dlinfo-1.2.1 fastapi-0.114.2 ffmpy-0.4.0 gradio-4.44.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 isodate-0.6.1 language-tags-1.2.0 multiprocess-0.70.16 orjson-3.10.7 phonemizer-3.3.0 pyarrow-17.0.0 pydub-0.25.1 pylatexenc-2.10 python-multipart-0.0.9 rdflib-7.0.0 rfc3986-1.5.0 ruff-0.6.5 segments-2.2.1 semantic-version-2.10.0 starlette-0.38.5 timm-1.0.9 tomlkit-0.12.0 uvicorn-0.30.6 websockets-12.0 xxhash-3.5.0\n",
            "Collecting audiocraft\n",
            "  Cloning https://****@github.com/facebookresearch/audiocraft to /tmp/pip-install-tjrvrkxj/audiocraft_e4515e288a7343fdb2c0fad78ab07de7\n",
            "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/facebookresearch/audiocraft' /tmp/pip-install-tjrvrkxj/audiocraft_e4515e288a7343fdb2c0fad78ab07de7\n",
            "  Resolved https://****@github.com/facebookresearch/audiocraft to commit adf0b04a4452f171970028fcf80f101dd5e26e19\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av==11.0.0 (from audiocraft)\n",
            "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from audiocraft) (0.8.0)\n",
            "Collecting flashy>=0.0.1 (from audiocraft)\n",
            "  Downloading flashy-0.0.2.tar.gz (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core>=1.1 (from audiocraft)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting hydra_colorlog (from audiocraft)\n",
            "  Downloading hydra_colorlog-1.2.0-py3-none-any.whl.metadata (949 bytes)\n",
            "Collecting julius (from audiocraft)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words (from audiocraft)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from audiocraft) (1.26.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from audiocraft) (0.1.99)\n",
            "Requirement already satisfied: spacy>=3.6.1 in /usr/local/lib/python3.10/dist-packages (from audiocraft) (3.7.6)\n",
            "Collecting torch==2.1.0 (from audiocraft)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchaudio<2.1.2,>=2.0.0 (from audiocraft)\n",
            "  Downloading torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from audiocraft) (0.24.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audiocraft) (4.66.5)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from audiocraft) (4.44.2)\n",
            "Collecting xformers<0.0.23 (from audiocraft)\n",
            "  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting demucs (from audiocraft)\n",
            "  Downloading demucs-4.0.1.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from audiocraft) (0.10.2.post1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from audiocraft) (0.12.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from audiocraft) (4.44.0)\n",
            "Collecting torchmetrics (from audiocraft)\n",
            "  Downloading torchmetrics-1.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting encodec (from audiocraft)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from audiocraft) (3.20.3)\n",
            "Collecting torchvision==0.16.0 (from audiocraft)\n",
            "  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchtext==0.16.0 (from audiocraft)\n",
            "  Downloading torchtext-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting pesq (from audiocraft)\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pystoi (from audiocraft)\n",
            "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->audiocraft) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->audiocraft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->audiocraft) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->audiocraft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->audiocraft) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->audiocraft) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->audiocraft)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16.0->audiocraft) (2.32.3)\n",
            "Collecting torchdata==0.7.0 (from torchtext==0.16.0->audiocraft)\n",
            "  Downloading torchdata-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0->audiocraft) (9.4.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->audiocraft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext==0.16.0->audiocraft) (2.0.7)\n",
            "Collecting dora-search (from flashy>=0.0.1->audiocraft)\n",
            "  Downloading dora_search-0.1.12.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from flashy>=0.0.1->audiocraft) (6.8.2)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.1->audiocraft)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->audiocraft)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->audiocraft) (24.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (0.12.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (2.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (71.0.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.6.1->audiocraft) (3.4.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio<2.1.2,>=2.0.0 (from audiocraft)\n",
            "  Downloading torchaudio-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->audiocraft) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->audiocraft) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->audiocraft) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->audiocraft) (0.19.1)\n",
            "Collecting lameenc>=1.2 (from demucs->audiocraft)\n",
            "  Downloading lameenc-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (803 bytes)\n",
            "Collecting openunmix (from demucs->audiocraft)\n",
            "  Downloading openunmix-1.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (0.114.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (6.4.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (3.10.7)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (2.1.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (0.6.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (0.12.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->audiocraft) (0.30.6)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio->audiocraft) (12.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->audiocraft) (1.0.8)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->audiocraft) (1.17.1)\n",
            "Collecting docopt>=0.6.2 (from num2words->audiocraft)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->audiocraft)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->audiocraft) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->audiocraft) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->audiocraft) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->audiocraft) (2.22)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio->audiocraft) (0.38.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->audiocraft) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->audiocraft) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->audiocraft) (0.14.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.6.1->audiocraft) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audiocraft) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audiocraft) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audiocraft) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audiocraft) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audiocraft) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->audiocraft) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->audiocraft) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->audiocraft) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->audiocraft) (2024.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->audiocraft) (4.3.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.6.1->audiocraft) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.6.1->audiocraft) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.16.0->audiocraft) (3.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->audiocraft) (3.5.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.6.1->audiocraft) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.6.1->audiocraft) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.6.1->audiocraft) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.6.1->audiocraft) (7.0.4)\n",
            "Collecting retrying (from dora-search->flashy>=0.0.1->audiocraft)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting submitit (from dora-search->flashy>=0.0.1->audiocraft)\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting treetable (from dora-search->flashy>=0.0.1->audiocraft)\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->audiocraft) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.6.1->audiocraft) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->audiocraft) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.6.1->audiocraft) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->dora-search->flashy>=0.0.1->audiocraft) (2.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (0.1.2)\n",
            "Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.16.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.1.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_colorlog-1.2.0-py3-none-any.whl (3.6 kB)\n",
            "Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading torchmetrics-1.4.2-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lameenc-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openunmix-1.3.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: audiocraft, flashy, antlr4-python3-runtime, demucs, julius, encodec, pesq, docopt, dora-search, treetable\n",
            "  Building wheel for audiocraft (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for audiocraft: filename=audiocraft-1.4.0a1-py3-none-any.whl size=292929 sha256=a992474ca7ad11350172327ca5c8cb0b9ef996347593f55f83fa44d3fe10cdc1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t792nsvp/wheels/61/bb/15/cf53514254501b4472fb64d137bd3ab88737daf6917dfcbdc9\n",
            "  Building wheel for flashy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashy: filename=flashy-0.0.2-py3-none-any.whl size=34526 sha256=7b5c1a88434008acf48730da6aea41db2f2144725abe66fdef7f84ad836669d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/bd/3d/16c6bc059203299f37b6014643b739afb7f6d1be13a94fc2f7\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=f8ef24564866b3be6ac788ad6c7fd12b64ace132cbd2c31c752225d213e09528\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demucs: filename=demucs-4.0.1-py3-none-any.whl size=78388 sha256=f497da14d7eef661bef81ab8cc44002ad369832cf4054165b6a265b623a075d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/65/a1/6cc0e525a84375af3b09823b3326b0ece53c4e68302c054548\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=8fa8d0bfd75d526b3f65c0b8a23ddb92dcca27fcc610d542e9d8d58f7403383f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=7c30c8e9468e34eeedfb0774a3901f307c9eef6bed1edea880ef522363f355b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.4-cp310-cp310-linux_x86_64.whl size=262948 sha256=7be7fce9ffed9bae7bbda79831f3b21f301fefac1562226fcdbe0306ef3b4f99\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/4e/2c/251524370c0fdd659e99639a0fbd0ca5a782c3aafcd456b28d\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=9b9fd478410e69a00923efaaeea6ad6c26d8a69c2427d51802905bdbd39cb76d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75092 sha256=f7b97380215c0dc70a41edd3a90f58e0a3c6056699ca41537612a5c174d066f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c2/c0/bea5cc405497284d584b958f293ef32c23bad42ae5e44d973c\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7332 sha256=bc7a6570b359885994ec1b53c1d2001b58f4d3b88c69dfab766eda8825981332\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/55/0e/91c3655bdb162446f8a7cd477579397544454a63ae7c599c0c\n",
            "Successfully built audiocraft flashy antlr4-python3-runtime demucs julius encodec pesq docopt dora-search treetable\n",
            "Installing collected packages: pesq, lameenc, docopt, antlr4-python3-runtime, triton, treetable, submitit, retrying, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, num2words, lightning-utilities, av, pystoi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, hydra_colorlog, torch, xformers, torchvision, torchmetrics, torchdata, torchaudio, julius, dora-search, torchtext, openunmix, flashy, encodec, demucs, audiocraft\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0+cu121\n",
            "    Uninstalling torch-2.4.0+cu121:\n",
            "      Successfully uninstalled torch-2.4.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.19.0+cu121\n",
            "    Uninstalling torchvision-0.19.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.19.0+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.4.0+cu121\n",
            "    Uninstalling torchaudio-2.4.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.4.0+cu121\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 audiocraft-1.4.0a1 av-11.0.0 demucs-4.0.1 docopt-0.6.2 dora-search-0.1.12 encodec-0.1.1 flashy-0.0.2 hydra-core-1.3.2 hydra_colorlog-1.2.0 julius-0.2.7 lameenc-1.7.0 lightning-utilities-0.11.7 num2words-0.5.13 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 openunmix-1.3.0 pesq-0.0.4 pystoi-0.4.1 retrying-1.3.4 submitit-1.5.1 torch-2.1.0 torchaudio-2.1.0 torchdata-0.7.0 torchmetrics-1.4.2 torchtext-0.16.0 torchvision-0.16.0 treetable-0.2.5 triton-2.1.0 xformers-0.0.22.post7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "419322c3a24d481fa7208d167d3206e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VoiceCraft'...\n",
            "remote: Enumerating objects: 508, done.\u001b[K\n",
            "remote: Counting objects: 100% (272/272), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 508 (delta 182), reused 196 (delta 132), pack-reused 236 (from 1)\u001b[K\n",
            "Receiving objects: 100% (508/508), 2.98 MiB | 4.38 MiB/s, done.\n",
            "Resolving deltas: 100% (294/294), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers huggingface_hub accelerate datasets numpy pillow safetensors tokenizers torch torchaudio torchvision tqdm timm matplotlib phonemizer gradio\n",
        "!pip install -U git+https://git@github.com/facebookresearch/audiocraft#egg=audiocraft\n",
        "!git clone https://github.com/jasonppy/VoiceCraft.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simply installing audiocraft breaks due to no config, so move the default into site-packages\n",
        "%cd /content/VoiceCraft\n",
        "!git clone https://github.com/facebookresearch/audiocraft.git\n",
        "!mv audiocraft/config /usr/local/lib/python3.10/dist-packages/\n",
        "!rm -rf audiocraft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNNvOSD8-_rn",
        "outputId": "cc5c01c7-1e79-484b-f65d-8b5b875bfd44"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VoiceCraft\n",
            "Cloning into 'audiocraft'...\n",
            "remote: Enumerating objects: 1600, done.\u001b[K\n",
            "remote: Counting objects: 100% (658/658), done.\u001b[K\n",
            "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
            "remote: Total 1600 (delta 478), reused 433 (delta 433), pack-reused 942 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1600/1600), 2.03 MiB | 28.80 MiB/s, done.\n",
            "Resolving deltas: 100% (902/902), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!mkdir -p training_data\n",
        "!mkdir -p training_data/dataset\n",
        "!mkdir -p training_data/dataset/flickr30k\n",
        "!mkdir -p training_data/dataset/mscoco\n",
        "!mkdir -p training_data/checkpoints\n",
        "!mkdir -p training_data/pretrained_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pat60p2oXXNi",
        "outputId": "d5793ccb-9b3c-48aa-8a73-c1fbf81435a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s6G8aw8YSFT",
        "outputId": "33851be1-8c2d-46d8-f1b0-983c72d0bb99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d hsankesara/flickr-image-dataset\n",
        "!unzip -qo flickr-image-dataset.zip\n",
        "!rm -rf flickr-image-dataset.zip\n",
        "!mv -f /content/flickr30k_images/flickr30k_images /content/training_data/dataset/flickr30k/images\n",
        "!mv -f /content/flickr30k_images/results.csv /content/training_data/dataset/flickr30k\n",
        "!rm -rf /content/flickr30k_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nt0iz8zYcOj",
        "outputId": "d30dad73-736a-4594-d93d-c399c96b8f05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/hsankesara/flickr-image-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading flickr-image-dataset.zip to /content\n",
            "100% 8.16G/8.16G [06:50<00:00, 24.0MB/s]\n",
            "100% 8.16G/8.16G [06:50<00:00, 21.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/VoiceCraft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aZ296UNi6u8",
        "outputId": "effba997-7e0c-48de-e3a0-ec27e86fd4a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VoiceCraft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "os.environ[\"USER\"] = \"nsandiman\"\n",
        "\n",
        "import io\n",
        "import torch\n",
        "import torchaudio\n",
        "from argparse import Namespace\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import transformers\n",
        "from typing import Tuple\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple, List, Dict\n",
        "import pickle\n",
        "import warnings\n",
        "import math\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "import requests\n",
        "from VoiceCraft.models import voicecraft\n",
        "from VoiceCraft.inference_tts_scale import inference_one_sample\n",
        "from VoiceCraft.data.tokenizer import (\n",
        "    AudioTokenizer,\n",
        "    TextTokenizer\n",
        ")\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "from num2words import num2words\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQnRsxk0EeWg",
        "outputId": "dde1a42c-620b-4290-9472-f6215cd6a7b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPlV754WjULL",
        "outputId": "5a935e9a-ecd7-4639-b6ed-33ae1cc5f363"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "\n",
        "    def __init__(self, tokenizer_name, special_tokens_dict=None) -> None:\n",
        "\n",
        "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "        if special_tokens_dict is None:\n",
        "           warnings.warn(f\"'special_tokens_dict' has not been set, using default special_tokens_dict\")\n",
        "           self.tokenizer.add_special_tokens({\n",
        "               \"bos_token\": \"[BOS]\",\n",
        "               \"eos_token\": \"[EOS]\",\n",
        "               \"pad_token\": \"[PAD]\"\n",
        "           })\n",
        "           self.vocab_size = self.tokenizer.vocab_size + 3\n",
        "           self.pad_token = '[PAD]'\n",
        "        else:\n",
        "            assert 'pad_token' in special_tokens_dict, ValueError(\"'pad_token' key must be present in the 'special_tokens_dict' passed\")\n",
        "            self.tokenizer.add_special_tokens(special_tokens_dict)\n",
        "            self.vocab_size = self.tokenizer.vocab_size + len(special_tokens_dict)\n",
        "            self.pad_token = special_tokens_dict['pad_token']\n",
        "\n",
        "    def encode(self, text, max_len, padding=True) -> Dict[str, torch.Tensor]:\n",
        "        return self.tokenizer(text, max_length=max_len, padding='max_length' if padding else True,\n",
        "                              return_tensors='pt')\n",
        "\n",
        "    def decode(self, token_ids) -> str:\n",
        "        return self.tokenizer.decode(token_ids)\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.encode(*args, **kwargs)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return self.tokenizer.get_vocab()\n",
        "\n",
        "    def save(self, file_path):\n",
        "        with open(file_path, \"wb\") as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(file_path):\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            return pickle.load(f)"
      ],
      "metadata": {
        "id": "3zig1hV-AhNR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    Extract patch embeddings from input images using a convolutional layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional layer to create patch embeddings\n",
        "        self.conv_patch_layer = nn.Conv2d(\n",
        "            in_channels=config['channels'],\n",
        "            out_channels=config['d_model'],\n",
        "            kernel_size=config['patch_size'],\n",
        "            stride=config['patch_size']\n",
        "        )\n",
        "\n",
        "        # Flatten patches into a 2D tensor for further processing\n",
        "        self.flatten = nn.Flatten(start_dim=2, end_dim=3)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Apply convolution to extract patch embeddings\n",
        "        patched_tensor = self.conv_patch_layer(x)\n",
        "\n",
        "        # Flatten the patched tensor\n",
        "        flattend_tensor = self.flatten(patched_tensor)\n",
        "\n",
        "        # Permute dimensions to match (B, num_patches, d_model) format\n",
        "        return flattend_tensor.permute(0, 2, 1)\n"
      ],
      "metadata": {
        "id": "KMGaoU5iA5wZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Create embeddings including positional and class tokens.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_embeddings = PatchEmbeddings(config)\n",
        "\n",
        "        self.class_token_embedding = nn.Parameter(\n",
        "            data=torch.randn(size=(1, 1, config['d_model'])),\n",
        "            requires_grad=True\n",
        "        )\n",
        "\n",
        "        self.positional_embedding = nn.Parameter(\n",
        "            data=torch.randn(size=(1, config['num_patches'] + 1, config['d_model'])),\n",
        "            requires_grad=True\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(config['emb_dropout'])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        patch_embed = self.patch_embeddings(x)\n",
        "\n",
        "        patch_embeddings_with_class_token = torch.cat(\n",
        "            tensors=(self.class_token_embedding.repeat(patch_embed.shape[0], 1, 1), patch_embed),\n",
        "            dim=1\n",
        "        )\n",
        "\n",
        "        return self.dropout(patch_embeddings_with_class_token + self.positional_embedding)\n",
        "\n"
      ],
      "metadata": {
        "id": "5gjHiMhSBFNT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MSABlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Multihead Self-Attention block.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Multihead self-attention layer\n",
        "        self.attn_block = nn.MultiheadAttention(\n",
        "            embed_dim=config[\"d_model\"],\n",
        "            num_heads=config[\"num_heads\"],\n",
        "            batch_first=True,\n",
        "            dropout=config['attn_dropout']\n",
        "        )\n",
        "\n",
        "        # Layer normalization for attention output\n",
        "        self.layer_norm = nn.LayerNorm(normalized_shape=config[\"d_model\"])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        attn_output, _ = self.attn_block(x, x, x)\n",
        "\n",
        "        return self.layer_norm(x + attn_output)\n"
      ],
      "metadata": {
        "id": "GqK_7xzABbti"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Feed-Forward Network block.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        d_model = config[\"d_model\"]\n",
        "\n",
        "        self.dense_net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=config['mlp_dropout']),\n",
        "            nn.Linear(d_model * 4, d_model)\n",
        "        )\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(normalized_shape=d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        return self.layer_norm(x + self.dense_net(x))\n"
      ],
      "metadata": {
        "id": "zN92vKa4BgtM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder block combining both Multihead Self-Attention and Feed-Forward Network blocks.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.msa_block = MSABlock(config)\n",
        "        self.mlp_block = MLPBlock(config)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        return self.mlp_block(self.msa_block(x))\n"
      ],
      "metadata": {
        "id": "K6fvqGfrBoy_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The Vision Transformer (ViT) encoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config[\"num_encoders\"])])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "y5h_yMbSBuPz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "    \"\"\"\n",
        "    Vision Transformer (ViT) model.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_layer = ViTEmbedding(config)\n",
        "        self.encoder = Encoder(config)\n",
        "\n",
        "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        embeddings = self.embedding_layer(images)\n",
        "\n",
        "        encoded_vectors = self.encoder(embeddings)\n",
        "\n",
        "        return encoded_vectors[:, 0, :]\n",
        "\n"
      ],
      "metadata": {
        "id": "aFm0FLGgB3S9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT decoder embedding class.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(\n",
        "            num_embeddings=config[\"vocab_size\"],\n",
        "            embedding_dim=config[\"d_model\"]\n",
        "        )\n",
        "\n",
        "        self.positional_encoding = nn.Parameter(\n",
        "            data=torch.randn(size=(1, config[\"context_length\"], config[\"d_model\"])),\n",
        "            requires_grad=True\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=config['emb_dropout'])\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        token_embeddings = self.token_embedding(tokens)\n",
        "        return self.dropout(self.positional_encoding[:, :tokens.shape[1], :] + token_embeddings)\n",
        "\n"
      ],
      "metadata": {
        "id": "FFkK-JiYCC3m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttnBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT causal self-attention block.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        assert config[\"d_model\"] % config[\"num_heads\"] == 0, \\\n",
        "            ValueError(f\"{config['d_model']} d_model should be exactly divisible by {config['num_heads']} num_heads\")\n",
        "\n",
        "        self.d_model = config[\"d_model\"]\n",
        "        self.head_dim = config[\"d_model\"] // config[\"num_heads\"]\n",
        "        self.num_heads = config[\"num_heads\"]\n",
        "        self.softmax_eps = config[\"softmax_eps\"]\n",
        "\n",
        "        self.projection_layer = nn.Linear(self.d_model, self.d_model * 3)\n",
        "        self.out_layer = nn.Linear(self.d_model, self.d_model)\n",
        "        self.layer_norm = nn.LayerNorm(normalized_shape=self.d_model)\n",
        "        self.attn_dropout = nn.Dropout(p=config['attn_dropout'])\n",
        "\n",
        "    def _safe_softmax(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        num = torch.exp(x)\n",
        "        denom = torch.exp(x).sum(dim=-1, keepdim=True) + self.softmax_eps\n",
        "        return num / denom\n",
        "\n",
        "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        B, CTX_LENGTH = x.shape[0], x.shape[1]\n",
        "        q, k, v = self.projection_layer(x).split(self.d_model, dim=2)  # B, CTX_LENGTH, d_model\n",
        "        q = q.view(B, CTX_LENGTH, self.num_heads, self.head_dim).transpose(1, 2)  # B, num_heads, CTX_LENGTH, head_dim\n",
        "        k = k.view(B, CTX_LENGTH, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, CTX_LENGTH, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        q_k_prod = (q @ k.transpose(2, 3)) + attn_mask.unsqueeze(1)  # B, num_heads, CTX_LENGTH, CTX_LENGTH\n",
        "        wts = self._safe_softmax(q_k_prod / math.sqrt(self.head_dim))  # B, num_heads, CTX_LENGTH, CTX_LENGTH\n",
        "        wts = self.attn_dropout(wts)\n",
        "        attn_outputs = wts @ v  # B, num_heads, CTX_LENGTH, head_dim\n",
        "        y = attn_outputs.transpose(1, 2).contiguous().view(B, CTX_LENGTH, -1)\n",
        "        return self.layer_norm(x + self.out_layer(y))\n",
        "\n"
      ],
      "metadata": {
        "id": "DsIfV5GiCMa9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttnBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT cross-attention block.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        assert config[\"d_model\"] % config[\"num_heads\"] == 0, \\\n",
        "            ValueError(f\"{config['d_model']} d_model must be divisible by {config['num_heads']} num_heads\")\n",
        "\n",
        "        self.d_model = config['d_model']\n",
        "        self.num_heads = config['num_heads']\n",
        "        self.head_dim = self.d_model // self.num_heads\n",
        "        self.q_proj = nn.Linear(self.d_model, self.d_model)\n",
        "        self.k_proj = nn.Linear(self.d_model, self.d_model)\n",
        "        self.v_proj = nn.Linear(self.d_model, self.d_model)\n",
        "        self.projection_layer = nn.Linear(self.d_model, self.d_model)\n",
        "        self.layer_norm = nn.LayerNorm(normalized_shape=self.d_model)\n",
        "        self.attn_dropout = nn.Dropout(p=config['attn_dropout'])\n",
        "\n",
        "    def forward(self, x: torch.Tensor, image_encoding: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        B, CTX_LENGTH, _ = x.shape\n",
        "\n",
        "        q = self.q_proj(x).view(B, CTX_LENGTH, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # B, num_heads, CTX_LENGTH, head_dim\n",
        "        k = self.k_proj(image_encoding).view(B, 1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # B, num_heads, 1, head_dim\n",
        "        v = self.v_proj(image_encoding).view(B, 1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)  # B, num_heads, 1, head_dim\n",
        "\n",
        "        wts = F.softmax((q @ k.transpose(2, 3)) / math.sqrt(self.head_dim), dim=-1)  # B, num_heads, CTX_LENGTH, 1\n",
        "        wts = self.attn_dropout(wts)\n",
        "        y = wts @ v  # B, num_heads, CTX_LENGTH, head_dim\n",
        "        y = y.transpose(1, 2).contiguous().view(B, CTX_LENGTH, -1)  # B, CTX_LENGTH, d_model\n",
        "        return self.layer_norm(x + self.projection_layer(y))\n"
      ],
      "metadata": {
        "id": "PafoHuadCSY6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT decoder block.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.csa_block = CausalSelfAttnBlock(config)\n",
        "        self.cross_attn_block = CrossAttnBlock(config)\n",
        "        self.mlp_block = MLPBlock(config)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, image_encoding: torch.Tensor, attn_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        csa_out = self.csa_block(x, attn_mask)\n",
        "        cross_out = self.cross_attn_block(csa_out, image_encoding)\n",
        "        mlp_out = self.mlp_block(cross_out)\n",
        "        return mlp_out\n",
        ""
      ],
      "metadata": {
        "id": "ysvXpgR_Cds4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT decoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.decoder_blocks = nn.ModuleList([GPTDecoderBlock(config) for _ in range(config[\"num_decoders\"])])\n",
        "\n",
        "    def forward(self, x: torch.Tensor, image_encoding: torch.Tensor, attn_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        for block in self.decoder_blocks:\n",
        "            x = block(x, image_encoding, attn_mask)\n",
        "\n",
        "        return x\n",
        ""
      ],
      "metadata": {
        "id": "auuUiv6DCmPk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "    \"\"\"\n",
        "    GPT model for image caption generation.\n",
        "    \"\"\"\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.device = config[\"device\"]\n",
        "        self.context_length = config[\"context_length\"]\n",
        "        self.softmax_eps = config[\"softmax_eps\"]\n",
        "        self.embedding = GPTEmbedding(config)\n",
        "        self.decoder = GPTDecoder(config)\n",
        "        self.cls_head = nn.Linear(config[\"d_model\"], config[\"vocab_size\"])\n",
        "        self.cls_head.weight = self.embedding.token_embedding.weight\n",
        "        # Removed weight tying as it led to slower convergence\n",
        "        self.ignore_index = config[\"ignore_index\"]\n",
        "\n",
        "    def _create_mask(self, context_length: int, attn_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        mask = torch.triu(\n",
        "            input=torch.ones(size=(context_length, context_length), requires_grad=False) * float(\"-inf\"),\n",
        "            diagonal=1\n",
        "        ).unsqueeze(0).repeat(attn_mask.shape[0], 1, 1)\n",
        "        mask = mask.to(self.device)\n",
        "        for i in range(mask.shape[0]):\n",
        "            mask[i, attn_mask[i].logical_not(), :] = float(\"-inf\")\n",
        "        return mask  # B, CTX_LENGTH, CTX_LENGTH\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor, image_encoding: torch.Tensor, attn_mask: torch.Tensor, targets: torch.Tensor = None) -> Tuple[torch.Tensor]:\n",
        "\n",
        "        embeddings = self.embedding(tokens)  # B, CTX_LENGTH, d_model\n",
        "        mask = self._create_mask(tokens.shape[1], attn_mask)\n",
        "        decoder_out = self.decoder(embeddings, image_encoding, mask)  # B, CTX_LENGTH, d_model\n",
        "        logits = self.cls_head(decoder_out)  # B, CTX_LENGTH, vocab_size\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), targets.reshape(-1), ignore_index=self.ignore_index)\n",
        "\n",
        "        return logits, loss\n",
        "\n"
      ],
      "metadata": {
        "id": "vU711hEHCsKp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageCaptioner(nn.Module):\n",
        "    \"\"\"\n",
        "    Vision language main class for image captioning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = config['device']\n",
        "        self.is_vit_pretrained = False\n",
        "\n",
        "        # Initialize Vision Transformer\n",
        "        if config['vit_kwargs'][\"pretrained_model_name\"] is not None:\n",
        "            self.is_vit_pretrained = True\n",
        "            self.vit = timm.create_model(\n",
        "                model_name=config['vit_kwargs'][\"pretrained_model_name\"],\n",
        "                pretrained=True,\n",
        "                num_classes=0,\n",
        "                global_pool='avg'\n",
        "            )\n",
        "            config[\"vit_kwargs\"][\"d_model\"] = self.vit.embed_dim\n",
        "        else:\n",
        "            self.vit = ViT(config['vit_kwargs'])\n",
        "\n",
        "        # Initialize GPT\n",
        "        self.gpt = GPT(config['gpt_kwargs'])\n",
        "\n",
        "        # Linear layer to map image encoding dimension to GPT's input dimension\n",
        "        self.dimension_mapping_layer = nn.Linear(config[\"vit_kwargs\"]['d_model'], config[\"gpt_kwargs\"]['d_model'])\n",
        "\n",
        "    def forward(self, image: torch.Tensor, tokens: torch.Tensor, attn_mask: torch.Tensor, targets: torch.Tensor=None) -> Tuple[torch.Tensor]:\n",
        "\n",
        "        # Encode image\n",
        "        image_encoding = self.vit(image)  # (B, d_model)\n",
        "\n",
        "        # Map image encoding to GPT's input dimension\n",
        "        dimension_mapped_image_encoding = self.dimension_mapping_layer(image_encoding[:, None, :])  # (B, 1, d_model)\n",
        "\n",
        "        # Forward pass through GPT\n",
        "        return self.gpt(tokens, dimension_mapped_image_encoding, attn_mask, targets)\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def generate(self,\n",
        "                 image: torch.Tensor,\n",
        "                 sos_token: int,\n",
        "                 eos_token: int,\n",
        "                 max_len: int=40) -> List[int]:\n",
        "\n",
        "        # Encode image\n",
        "        image_encoding = self.vit(image)  # (B, d_model)\n",
        "\n",
        "        # Map image encoding to GPT's input dimension\n",
        "        dimension_mapped_image_encoding = self.dimension_mapping_layer(image_encoding[:, None, :])  # (B, 1, d_model)\n",
        "\n",
        "        # Initialize tokens with the start-of-sequence token\n",
        "        tokens = torch.tensor([[sos_token]], requires_grad=False).to(self.device)\n",
        "        attn_mask = torch.tensor([[1]], requires_grad=False).to(self.device)\n",
        "\n",
        "        while tokens.shape[1] < max_len and tokens[0, -1] != eos_token:\n",
        "            # Forward pass through GPT\n",
        "            logits, _ = self.gpt(tokens, dimension_mapped_image_encoding, attn_mask, None)  # (1, N+1, vocab_size)\n",
        "\n",
        "            # Predict the next token\n",
        "            next_token = torch.argmax(logits[0, -1, :], dim=0).item()\n",
        "\n",
        "            # Append the predicted token to the sequence\n",
        "            tokens = torch.cat(\n",
        "                (tokens, torch.tensor([[next_token]], requires_grad=False)),\n",
        "                dim=-1\n",
        "            ).to(self.device)\n",
        "\n",
        "            # Update attention mask\n",
        "            attn_mask = torch.cat(\n",
        "                (attn_mask, torch.tensor([[1]], requires_grad=False)),\n",
        "                dim=-1\n",
        "            ).to(self.device)\n",
        "\n",
        "        return list(tokens[0])\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, checkpoint, device):\n",
        "\n",
        "        if not os.path.exists(checkpoint):\n",
        "            raise FileNotFoundError(f\"{checkpoint} does not exist\")\n",
        "\n",
        "        cp = torch.load(checkpoint, map_location=device)\n",
        "\n",
        "        # Update device information in the model configuration\n",
        "        cp['model_config']['device'] = device\n",
        "        cp['model_config']['vit_kwargs']['device'] = device\n",
        "        cp['model_config']['gpt_kwargs']['device'] = device\n",
        "\n",
        "        # Initialize model with configuration and load state_dict\n",
        "        model = cls(cp['model_config'])\n",
        "        model.load_state_dict(cp['model_state_dict'])\n",
        "        model = model.to(device)\n",
        "\n",
        "        return model\n",
        "\n"
      ],
      "metadata": {
        "id": "DycH1A6EDHYx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_console():\n",
        "    \"\"\"\n",
        "    Clears the console based on the operating system.\n",
        "    \"\"\"\n",
        "    if os.name == \"nt\":\n",
        "        os.system(\"cls\")\n",
        "    else:\n",
        "        os.system(\"clear\")\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"\n",
        "    Trainer class for image captioning model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_config, train_config, dls, tokenizer) -> None:\n",
        "\n",
        "        self.device = train_config[\"device\"]\n",
        "\n",
        "        # Load model from checkpoint if provided, else initialize a new model\n",
        "        if train_config[\"checkpoint\"] is not None:\n",
        "            self.model = ImageCaptioner(model_config).from_pretrained(\n",
        "                train_config[\"checkpoint\"], self.device\n",
        "            )\n",
        "        else:\n",
        "            self.model = ImageCaptioner(model_config).to(self.device)\n",
        "\n",
        "        self.train_config = train_config\n",
        "        self.model_config = model_config\n",
        "        self.train_dl, self.test_dl = dls\n",
        "        self.metrics = pd.DataFrame(\n",
        "            columns=[\n",
        "                \"epoch\",\n",
        "                \"train_loss\",\n",
        "                \"test_loss\",\n",
        "                \"train_perplexity\",\n",
        "                \"test_perplexity\",\n",
        "                \"elapsed_time\",\n",
        "            ]\n",
        "        )\n",
        "        self.tokenizer = tokenizer\n",
        "        self.writer = SummaryWriter(train_config[\"experiment_name\"])\n",
        "\n",
        "        # Transformation pipeline for images\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(\n",
        "                    size=(model_config[\"img_size\"], model_config[\"img_size\"])\n",
        "                ),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def fit(self, verbose=True):\n",
        "\n",
        "        global_step = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Freeze the pretrained ViT (Vision Transformer) parameters during initial epochs\n",
        "        if self.model.is_vit_pretrained and self.train_config[\"freeze_epochs\"] > 0:\n",
        "            for p in self.model.vit.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        # Set up optimizer with learning rates for different model parts\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            [\n",
        "                {\n",
        "                    \"params\": self.model.vit.parameters(),\n",
        "                    \"lr\": 0,\n",
        "                },  # Vit params are initially frozen\n",
        "                {\n",
        "                    \"params\": self.model.dimension_mapping_layer.parameters(),\n",
        "                    \"lr\": self.train_config[\"lr\"],\n",
        "                },\n",
        "                {\"params\": self.model.gpt.parameters(), \"lr\": self.train_config[\"lr\"]},\n",
        "            ],\n",
        "            weight_decay=self.train_config[\"weight_decay\"],\n",
        "        )\n",
        "\n",
        "        # Initial training with frozen ViT parameters\n",
        "        for epoch in range(self.train_config[\"freeze_epochs\"]):\n",
        "            train_loss, train_perplexity, global_step = self._train(epoch, global_step)\n",
        "            test_loss, test_perplexity, global_step = self._eval(epoch, global_step)\n",
        "            elapsed_time = time.time() - start_time\n",
        "            new_row = pd.DataFrame(\n",
        "                data={\n",
        "                    \"epoch\": [epoch + 1],\n",
        "                    \"train_loss\": [train_loss],\n",
        "                    \"test_loss\": [test_loss],\n",
        "                    \"elapsed_time\": [elapsed_time],\n",
        "                    \"train_perplexity\": [train_perplexity],\n",
        "                    \"test_perplexity\": [test_perplexity],\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Store training metrics\n",
        "            self.metrics = pd.concat([self.metrics, new_row], axis=0, ignore_index=True)\n",
        "\n",
        "            # Clear console and print metrics\n",
        "            clear_console()\n",
        "            print(self.metrics.to_string(index=False))\n",
        "\n",
        "        # Unfreeze the ViT parameters after initial epochs\n",
        "        if self.model.is_vit_pretrained and self.train_config[\"freeze_epochs\"] > 0:\n",
        "            for p in self.model.vit.parameters():\n",
        "                p.requires_grad = True\n",
        "\n",
        "        self.optimizer.param_groups[0][\"lr\"] = self.train_config[\n",
        "            \"lr\"\n",
        "        ]  # Unfreeze ViT params\n",
        "\n",
        "        # Further training with all parameters unfrozen\n",
        "        for epoch in range(\n",
        "            self.train_config[\"freeze_epochs\"], self.train_config[\"epochs\"]\n",
        "        ):\n",
        "            train_loss, train_perplexity, global_step = self._train(epoch, global_step)\n",
        "            test_loss, test_perplexity, global_step = self._eval(epoch, global_step)\n",
        "            elapsed_time = time.time() - start_time\n",
        "            new_row = pd.DataFrame(\n",
        "                data={\n",
        "                    \"epoch\": [epoch + 1],\n",
        "                    \"train_loss\": [train_loss],\n",
        "                    \"test_loss\": [test_loss],\n",
        "                    \"elapsed_time\": [elapsed_time],\n",
        "                    \"train_perplexity\": [train_perplexity],\n",
        "                    \"test_perplexity\": [test_perplexity],\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Store training metrics\n",
        "            self.metrics = pd.concat([self.metrics, new_row], axis=0, ignore_index=True)\n",
        "\n",
        "            # Clear console and print metrics\n",
        "            clear_console()\n",
        "            print(self.metrics.to_string(index=False))\n",
        "\n",
        "        # Save the final model checkpoint\n",
        "        self.save(\"/content/training_data/checkpoints/imagecraft.pt\")\n",
        "        return self.metrics\n",
        "\n",
        "    def _train(self, epoch, global_step):\n",
        "\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        train_batchiter = tqdm(\n",
        "            self.train_dl, desc=f\"Processing Training Epoch {epoch:02d}\"\n",
        "        )\n",
        "\n",
        "        for image, tokens, attn_mask in train_batchiter:\n",
        "            # Prepare inputs and targets\n",
        "            input_tokens, target_tokens = tokens[:, :-1], tokens[:, 1:]\n",
        "            attn_mask = attn_mask[:, :-1]\n",
        "            image, input_tokens, target_tokens, attn_mask = (\n",
        "                image.to(self.device),\n",
        "                input_tokens.to(self.device),\n",
        "                target_tokens.to(self.device),\n",
        "                attn_mask.to(self.device),\n",
        "            )\n",
        "\n",
        "            # Forward pass and compute loss\n",
        "            _, loss = self.model(image, input_tokens, attn_mask, target_tokens)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Update progress bar with loss and perplexity\n",
        "            train_batchiter.set_postfix(\n",
        "                {\n",
        "                    \"Train Loss\": f\"{loss.item():6.3f}\",\n",
        "                    \"Train Perplexity\": f\"{torch.exp(torch.tensor(loss.item())).item()}\",\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Log the Loss to TensorBoard\n",
        "            self.writer.add_scalar(\"Loss/train\", loss.item(), global_step)\n",
        "            self.writer.flush()\n",
        "\n",
        "            # Backpropagation and optimizer step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        # Compute average loss and perplexity\n",
        "        avg_loss = total_loss / len(self.train_dl)\n",
        "        train_perplexity = torch.exp(torch.tensor(avg_loss))\n",
        "        return avg_loss, train_perplexity.item(), global_step\n",
        "\n",
        "    def _eval(self, epoch, global_step):\n",
        "\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        test_batchiter = tqdm(self.test_dl, desc=f\"Processing Eval Epoch {epoch:02d}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for image, tokens, attn_mask in test_batchiter:\n",
        "                # Prepare inputs and targets\n",
        "                input_tokens, target_tokens = tokens[:, :-1], tokens[:, 1:]\n",
        "                attn_mask = attn_mask[:, :-1]\n",
        "                image, input_tokens, target_tokens, attn_mask = (\n",
        "                    image.to(self.device),\n",
        "                    input_tokens.to(self.device),\n",
        "                    target_tokens.to(self.device),\n",
        "                    attn_mask.to(self.device),\n",
        "                )\n",
        "\n",
        "                # Forward pass and compute loss\n",
        "                _, loss = self.model(image, input_tokens, attn_mask, target_tokens)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # Update progress bar with loss and perplexity\n",
        "                test_batchiter.set_postfix(\n",
        "                    {\n",
        "                        \"Test Loss\": f\"{loss.item():6.3f}\",\n",
        "                        \"Test Perplexity\": f\"{torch.exp(torch.tensor(loss.item())).item()}\",\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # Log the Loss to TensorBoard\n",
        "                self.writer.add_scalar(\"Loss/eval\", loss.item(), global_step)\n",
        "                self.writer.flush()\n",
        "\n",
        "                global_step += 1\n",
        "\n",
        "        # Compute average loss and perplexity\n",
        "        avg_loss = total_loss / len(self.test_dl)\n",
        "        test_perplexity = torch.exp(torch.tensor(avg_loss))\n",
        "        return avg_loss, test_perplexity.item(), global_step\n",
        "\n",
        "    def inference(self, image_path, max_len) -> str:\n",
        "\n",
        "        # Preprocess image\n",
        "        image_tensor = (\n",
        "            self.transform(Image.open(image_path)).unsqueeze(0).to(self.device)\n",
        "        )\n",
        "\n",
        "        # Generate tokens using the model\n",
        "        tokens = self.model.generate(\n",
        "            image_tensor,\n",
        "            sos_token=self.tokenizer.get_vocab()[\"[BOS]\"],\n",
        "            eos_token=self.tokenizer.get_vocab()[\"[EOS]\"],\n",
        "            max_len=max_len,\n",
        "        )\n",
        "\n",
        "        # Decode tokens to generate caption\n",
        "        return self.tokenizer.decode(token_ids=[token.item() for token in tokens])\n",
        "\n",
        "    def save(self, file_path):\n",
        "\n",
        "        checkpoint = {\n",
        "            \"model_state_dict\": self.model.state_dict(),\n",
        "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
        "            \"train_config\": self.train_config,\n",
        "            \"model_config\": self.model_config,\n",
        "        }\n",
        "\n",
        "        torch.save(checkpoint, file_path)\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        \"\"\"\n",
        "        Plots and saves training and test loss and perplexity metrics.\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Plot training and test loss\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.metrics[\"epoch\"], self.metrics[\"train_loss\"], label=\"Train Loss\")\n",
        "        plt.plot(self.metrics[\"epoch\"], self.metrics[\"test_loss\"], label=\"Test Loss\")\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.title(\"Training and Test Loss Over Epochs\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Plot training and test perplexity\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(\n",
        "            self.metrics[\"epoch\"],\n",
        "            self.metrics[\"train_perplexity\"],\n",
        "            label=\"Train Perplexity\",\n",
        "        )\n",
        "        plt.plot(\n",
        "            self.metrics[\"epoch\"],\n",
        "            self.metrics[\"test_perplexity\"],\n",
        "            label=\"Test Perplexity\",\n",
        "        )\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(\"perplexity\")\n",
        "        plt.title(\"Training and Test Perplexity Over Epochs\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"/content/training_data/checkpoints/metrics.png\")\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lKi5lD8GJuHd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageCaptionerPipeline:\n",
        "    \"\"\"\n",
        "    A pipeline for predicting image captions using a pre-trained image captioning model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint: str, max_len: int, device: str, tokenizer=None):\n",
        "\n",
        "        if tokenizer is None:\n",
        "            # Initialize the tokenizer if not provided\n",
        "            self.tokenizer = Tokenizer(\n",
        "                tokenizer_name=\"gpt2\",\n",
        "                special_tokens_dict={\n",
        "                    \"bos_token\": \"[BOS]\",\n",
        "                    \"eos_token\": \"[EOS]\",\n",
        "                    \"pad_token\": \"[PAD]\",\n",
        "                },\n",
        "            )\n",
        "        else:\n",
        "            self.tokenizer = tokenizer\n",
        "\n",
        "        # Update model configuration with tokenizer-specific settings\n",
        "        config[\"gpt_kwargs\"][\"vocab_size\"] = self.tokenizer.vocab_size\n",
        "        config[\"gpt_kwargs\"][\"ignore_index\"] = self.tokenizer.get_vocab()[\n",
        "            self.tokenizer.pad_token\n",
        "        ]\n",
        "        self.max_len = max_len\n",
        "        self.device = device\n",
        "\n",
        "        self.model = ImageCaptioner(config).from_pretrained(checkpoint, device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(size=(config[\"img_size\"], config[\"img_size\"])),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def inference(self, image_path: str) -> str:\n",
        "\n",
        "        # Load and transform the image\n",
        "        image_tensor = (\n",
        "            self.transform(Image.open(image_path)).unsqueeze(0).to(self.device)\n",
        "        )\n",
        "\n",
        "        # Generate caption using the model\n",
        "        tokens = self.model.generate(\n",
        "            image_tensor,\n",
        "            sos_token=self.tokenizer.get_vocab()[\"[BOS]\"],\n",
        "            eos_token=self.tokenizer.get_vocab()[\"[EOS]\"],\n",
        "            max_len=self.max_len,\n",
        "        )\n",
        "\n",
        "        # Decode the generated token IDs to a caption string\n",
        "        return self.tokenizer.decode(token_ids=[token.item() for token in tokens[1:-1]])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MsqonnGxG-6u"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VoiceCraftTTSPipeline:\n",
        "    \"\"\"\n",
        "    A voicecraft pipeline for converting text to speech.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name=\"gigaHalfLibri330M_TTSEnhanced_max16s.pth\",\n",
        "        encodec_fn=\"encodec_4cb2048_giga.th\",\n",
        "    ):\n",
        "        model = voicecraft.VoiceCraft.from_pretrained(\n",
        "            f\"pyp1/VoiceCraft_{model_name.replace('.pth', '')}\"\n",
        "        )\n",
        "\n",
        "        encodec_path = f\"/content/training_data/pretrained_models/{encodec_fn}\"\n",
        "\n",
        "        if not os.path.exists(encodec_path):\n",
        "            os.system(\n",
        "                f\"wget https://huggingface.co/pyp1/VoiceCraft/resolve/main/encodec_4cb2048_giga.th\"\n",
        "            )\n",
        "            os.system(\n",
        "                f\"mv encodec_4cb2048_giga.th /content/training_data/pretrained_models/encodec_4cb2048_giga.th\"\n",
        "            )\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        self.audio_tokenizer = AudioTokenizer(\n",
        "            signature=encodec_path, device=self.device\n",
        "        )\n",
        "        self.text_tokenizer = TextTokenizer(backend=\"espeak\")\n",
        "\n",
        "        self.phn2num = model.args.phn2num\n",
        "        self.config = vars(model.args)\n",
        "        model.to(self.device)\n",
        "        self.model = model\n",
        "\n",
        "        self.orig_audio = \"/content/VoiceCraft/demo/84_121550_000074_000000.wav\"\n",
        "        self.orig_transcript = \"But when I had approached so near to them The common object, which the sense deceives, Lost not by distance any of its marks\"\n",
        "        self.cut_off_sec = 67.87\n",
        "\n",
        "        self.codec_audio_sr = 16000\n",
        "        self.codec_sr = 50\n",
        "        self.top_k = 0\n",
        "        self.top_p = 0.9\n",
        "        self.temperature = 1\n",
        "        self.silence_tokens = [1388, 1898, 131]\n",
        "        self.kvcache = 1\n",
        "        self.stop_repetition = 3\n",
        "        self.sample_batch_size = 2\n",
        "        self.seed = 1\n",
        "\n",
        "    def generate(self, text):\n",
        "\n",
        "        text = replace_numbers_with_words(text).replace(\"  \", \" \").replace(\"  \", \" \")\n",
        "\n",
        "        sentences = sent_tokenize(text.replace(\"\\n\", \" \"))\n",
        "\n",
        "        info = torchaudio.info(self.orig_audio)\n",
        "        audio_dur = info.num_frames / info.sample_rate\n",
        "\n",
        "        audio_tensors = []\n",
        "        transcript = \"\"\n",
        "\n",
        "        for sentence in tqdm(sentences):\n",
        "            decode_config = {\n",
        "                \"top_k\": self.top_k,\n",
        "                \"top_p\": self.top_p,\n",
        "                \"temperature\": self.temperature,\n",
        "                \"stop_repetition\": self.stop_repetition,\n",
        "                \"kvcache\": self.kvcache,\n",
        "                \"codec_audio_sr\": self.codec_audio_sr,\n",
        "                \"codec_sr\": self.codec_sr,\n",
        "                \"silence_tokens\": self.silence_tokens,\n",
        "                \"sample_batch_size\": self.sample_batch_size,\n",
        "            }\n",
        "            transcript = self.orig_transcript\n",
        "            transcript += sentence + \"\\n\"\n",
        "\n",
        "            prompt_end_frame = int(min(audio_dur, self.cut_off_sec) * info.sample_rate)\n",
        "\n",
        "            transcript = (\n",
        "                replace_numbers_with_words(transcript)\n",
        "                .replace(\"  \", \" \")\n",
        "                .replace(\"  \", \" \")\n",
        "            )\n",
        "\n",
        "            _, gen_audio = inference_one_sample(\n",
        "                self.model,\n",
        "                Namespace(**self.config),\n",
        "                self.phn2num,\n",
        "                self.text_tokenizer,\n",
        "                self.audio_tokenizer,\n",
        "                self.orig_audio,\n",
        "                transcript,\n",
        "                self.device,\n",
        "                decode_config,\n",
        "                prompt_end_frame,\n",
        "            )\n",
        "            gen_audio = gen_audio[0].cpu()\n",
        "            audio_tensors.append(gen_audio)\n",
        "\n",
        "        output_audio = get_output_audio(audio_tensors, self.codec_audio_sr)\n",
        "        return output_audio\n",
        "\n"
      ],
      "metadata": {
        "id": "xXJoq0cpWgkd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageCraft:\n",
        "    \"\"\"\n",
        "    The imagecraft main class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, checkpoint: str, max_len: int, device: str, tokenizer=None):\n",
        "\n",
        "        if tokenizer is None:\n",
        "            # Initialize the tokenizer if not provided\n",
        "            self.tokenizer = Tokenizer(\n",
        "                tokenizer_name=\"gpt2\",\n",
        "                special_tokens_dict={\n",
        "                    \"bos_token\": \"[BOS]\",\n",
        "                    \"eos_token\": \"[EOS]\",\n",
        "                    \"pad_token\": \"[PAD]\",\n",
        "                },\n",
        "            )\n",
        "        else:\n",
        "            self.tokenizer = tokenizer\n",
        "\n",
        "        # Update model configuration with tokenizer-specific settings\n",
        "        config[\"gpt_kwargs\"][\"vocab_size\"] = self.tokenizer.vocab_size\n",
        "        config[\"gpt_kwargs\"][\"ignore_index\"] = self.tokenizer.get_vocab()[\n",
        "            self.tokenizer.pad_token\n",
        "        ]\n",
        "        self.max_len = max_len\n",
        "        self.device = device\n",
        "\n",
        "        self.model = ImageCaptioner(config).from_pretrained(checkpoint, device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(size=(config[\"img_size\"], config[\"img_size\"])),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def generate(self, image_path: str) -> str:\n",
        "\n",
        "        # Load and transform the image\n",
        "        image_tensor = (\n",
        "            self.transform(Image.open(image_path)).unsqueeze(0).to(self.device)\n",
        "        )\n",
        "\n",
        "        # Generate caption using the model\n",
        "        tokens = self.model.generate(\n",
        "            image_tensor,\n",
        "            sos_token=self.tokenizer.get_vocab()[\"[BOS]\"],\n",
        "            eos_token=self.tokenizer.get_vocab()[\"[EOS]\"],\n",
        "            max_len=self.max_len,\n",
        "        )\n",
        "\n",
        "        # Decode the generated token IDs to a caption string\n",
        "        decoded_caption = self.tokenizer.decode(token_ids=[token.item() for token in tokens[1:-1]])\n",
        "        voicecraft_pipeline = VoiceCraftTTSPipeline()\n",
        "        return voicecraft_pipeline.generate(decoded_caption)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BsHyIC3Yvv0Y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CaptionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame, image_size: int, context_length: int, tokenizer) -> None:\n",
        "\n",
        "        assert dataframe.columns[0] == 'image_name', ValueError(\"The first column should be the path to the image\")\n",
        "        assert dataframe.columns[1] == \"caption\", ValueError(\"The second column should be named 'caption'\")\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.context_length = context_length\n",
        "        self.df = dataframe\n",
        "\n",
        "        # Transformation pipeline for images\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(size=(image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "\n",
        "        image, text = Image.open(self.df.iloc[idx, 0]), self.df.iloc[idx, 1]\n",
        "        image_tensor = self.transform(image)  # Apply transformations to the image\n",
        "        op = self.tokenizer(text, max_len=self.context_length + 1)  # Tokenize the caption\n",
        "        tokens, attention_mask = op['input_ids'].squeeze(), op['attention_mask'].squeeze()\n",
        "        return image_tensor, tokens, attention_mask"
      ],
      "metadata": {
        "id": "Q-xK1JHwDbhR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_numbers_with_words(sentence):\n",
        "    sentence = re.sub(r\"(\\d+)\", r\" \\1 \", sentence)\n",
        "\n",
        "    def replace_with_words(match):\n",
        "        num = match.group(0)\n",
        "        try:\n",
        "            return num2words(num)\n",
        "        except:\n",
        "            return num\n",
        "\n",
        "    return re.sub(r\"\\b\\d+\\b\", replace_with_words, sentence)\n",
        "\n",
        "\n",
        "def get_output_audio(audio_tensors, codec_audio_sr):\n",
        "\n",
        "    result = torch.cat(audio_tensors, 1)\n",
        "    buffer = io.BytesIO()\n",
        "    torchaudio.save(buffer, result, int(codec_audio_sr), format=\"wav\")\n",
        "    buffer.seek(0)\n",
        "    return buffer.read()\n",
        "\n",
        "def process_flickr30k(csv_file_path: str, image_folder: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_file_path, delimiter=\"|\")\n",
        "    df.drop_duplicates(subset=['image_name'], inplace=True)\n",
        "    df.drop(columns=\" comment_number\", axis=1, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    df.rename({\" comment\": \"caption\"}, axis=1, inplace=True)\n",
        "    df.iloc[:, 0] = image_folder + \"/\" + df.iloc[:, 0]\n",
        "    df[\"caption\"] = \"[BOS] \" + df[\"caption\"] + \" [EOS]\"\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def process_and_save_flickr30k(csv_file_path: str, image_folder: str):\n",
        "    dataset_path = \"/content/training_data/dataset/flickr30k/preprocessed_data.csv\"\n",
        "    df = pd.read_csv(csv_file_path, delimiter=\"|\")\n",
        "    # df.drop_duplicates(subset=['image_name'], inplace=True)\n",
        "    df.drop(columns=\" comment_number\", axis=1, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    df.rename({\" comment\": \"caption\"}, axis=1, inplace=True)\n",
        "    df.iloc[:, 0] = image_folder + \"/\" + df.iloc[:, 0]\n",
        "    df[\"caption\"] = \"[BOS] \" + df[\"caption\"] + \" [EOS]\"\n",
        "    df.to_csv(dataset_path, index=False)\n",
        "    return dataset_path\n",
        "\n",
        "\n",
        "def train_test_split(\n",
        "    train_config: dict, model_config: dict, data: pd.DataFrame, tokenizer\n",
        ") -> Tuple[DataLoader, DataLoader]:\n",
        "    idxs = set(range(data.shape[0]))\n",
        "\n",
        "    # Randomly split indices for training and testing\n",
        "    train_idxs = random.sample(\n",
        "        sorted(idxs), k=int(len(idxs) * train_config[\"train_size\"])\n",
        "    )\n",
        "    test_idxs = list(idxs.difference(set(train_idxs)))\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    train_data = data.copy(deep=True).iloc[train_idxs, :].reset_index(drop=True)\n",
        "    test_data = data.copy(deep=True).iloc[test_idxs, :].reset_index(drop=True)\n",
        "\n",
        "    # Create dataset objects for training and testing\n",
        "    train_dataset = CaptionDataset(\n",
        "        dataframe=train_data,\n",
        "        image_size=model_config[\"img_size\"],\n",
        "        context_length=model_config[\"gpt_kwargs\"][\"context_length\"],\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    test_dataset = CaptionDataset(\n",
        "        dataframe=test_data,\n",
        "        image_size=model_config[\"img_size\"],\n",
        "        context_length=model_config[\"gpt_kwargs\"][\"context_length\"],\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    # Create DataLoader objects for training and testing datasets\n",
        "    train_dl = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=train_config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "    )\n",
        "\n",
        "    test_dl = DataLoader(\n",
        "        dataset=test_dataset, batch_size=train_config[\"batch_size\"], shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_dl, test_dl\n"
      ],
      "metadata": {
        "id": "-iA0mc6xDx2T"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration Parameters\n",
        "img_size = 224  # Image size (height and width) in pixels\n",
        "ctx_length = 256  # Length of the context (sequence length) for GPT\n",
        "num_encoders_vit = 8  # Number of encoder layers in the Vision Transformer\n",
        "num_heads_vit = 4  # Number of attention heads in the Vision Transformer\n",
        "ps = 16  # Patch size (height and width) for the Vision Transformer\n",
        "c = 3  # Number of color channels (RGB) in the image\n",
        "d_model_vit = ps**2 * c  # Dimension of the model (embedding dimension) for the Vision Transformer\n",
        "num_patches = (img_size * img_size) // (ps * ps)  # Number of patches in the input image\n",
        "d_model_gpt = 512  # Dimension of the model (embedding dimension) for GPT\n",
        "num_decoders_gpt = 8  # Number of decoder layers in GPT\n",
        "num_heads_gpt = 8  # Number of attention heads in GPT\n",
        "softmax_denom_eps = 1e-9  # Epsilon for numerical stability in softmax calculation\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Device to use (GPU if available, otherwise CPU)\n",
        "attn_dropout = 0.25  # Dropout probability for attention layers\n",
        "mlp_dropout = 0.25  # Dropout probability for the MLP layers\n",
        "emb_dropout = 0.25  # Dropout probability for the embedding layers\n",
        "\n",
        "# Vision Transformer Configuration\n",
        "vit_kwargs = {\n",
        "    \"num_encoders\": num_encoders_vit,  # Number of encoder layers\n",
        "    \"num_heads\": num_heads_vit,  # Number of attention heads\n",
        "    \"num_patches\": num_patches,  # Number of patches in the image\n",
        "    \"patch_size\": ps,  # Size of each patch\n",
        "    \"channels\": c,  # Number of input channels\n",
        "    \"d_model\": d_model_vit,  # Dimension of the model (embedding dimension)\n",
        "    \"pretrained_model_name\": None,  # Pretrained model name (None means no pretrained model)\n",
        "    \"device\": device,  # Device to use (GPU or CPU)\n",
        "    \"emb_dropout\": emb_dropout,  # Dropout probability for embedding layers\n",
        "    \"mlp_dropout\": mlp_dropout,  # Dropout probability for MLP layers\n",
        "    \"attn_dropout\": attn_dropout  # Dropout probability for attention layers\n",
        "}\n",
        "\n",
        "# GPT Configuration\n",
        "gpt_kwargs = {\n",
        "    \"d_model\": d_model_gpt,  # Dimension of the model (embedding dimension)\n",
        "    \"context_length\": ctx_length,  # Length of the context (sequence length)\n",
        "    \"num_decoders\": num_decoders_gpt,  # Number of decoder layers\n",
        "    \"softmax_eps\": softmax_denom_eps,  # Epsilon for numerical stability in softmax\n",
        "    \"num_heads\": num_heads_gpt,  # Number of attention heads\n",
        "    \"device\": device,  # Device to use (GPU or CPU)\n",
        "    \"emb_dropout\": emb_dropout,  # Dropout probability for embedding layers\n",
        "    \"mlp_dropout\": mlp_dropout,  # Dropout probability for MLP layers\n",
        "    \"attn_dropout\": attn_dropout  # Dropout probability for attention layers\n",
        "    # Add ignore_index and vocab_size before using in the model\n",
        "}\n",
        "\n",
        "# Complete Configuration\n",
        "config = {\n",
        "    \"vit_kwargs\": vit_kwargs,  # Vision Transformer configuration\n",
        "    \"gpt_kwargs\": gpt_kwargs,  # GPT configuration\n",
        "    \"device\": device,  # Device to use (GPU or CPU)\n",
        "    'img_size': img_size  # Image size\n",
        "}"
      ],
      "metadata": {
        "id": "4ak8DNCaDj2k"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/training_data/dataset/flickr30k/results.csv'\n",
        "image_folder = '/content/training_data/dataset/flickr30k/images'\n",
        "preprocessed_data = process_and_save_flickr30k(csv_file_path, image_folder)"
      ],
      "metadata": {
        "id": "vGGbK5bJikRg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = pd.read_csv(preprocessed_data)\n",
        "data = data[:5000]\n",
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer(\n",
        "    tokenizer_name=\"gpt2\",\n",
        "    special_tokens_dict={\n",
        "        \"bos_token\": \"[BOS]\",\n",
        "        \"eos_token\": \"[EOS]\",\n",
        "        \"pad_token\": \"[PAD]\",\n",
        "    },\n",
        ")\n",
        "\n",
        "img_size = 224\n",
        "\n",
        "# Set training configuration\n",
        "train_config = {\n",
        "    \"epochs\": 40,\n",
        "    \"freeze_epochs\": 2,\n",
        "    \"lr\": 2e-5,\n",
        "    \"device\": device,\n",
        "    \"weight_decay\": 1e-6,\n",
        "    \"experiment_name\": \"runs/tmodel\",\n",
        "    \"checkpoint\": None,\n",
        "    \"train_size\": 0.9,\n",
        "    \"batch_size\": 16,\n",
        "    \"device\": device,\n",
        "    \"max_len\": 40,\n",
        "}\n",
        "\n",
        "# Update model configuration with device and tokenizer information\n",
        "config[\"device\"] = device\n",
        "config[\"img_size\"] = img_size\n",
        "config[\"gpt_kwargs\"][\"device\"] = device\n",
        "config[\"vit_kwargs\"][\"device\"] = device\n",
        "config[\"gpt_kwargs\"][\"vocab_size\"] = tokenizer.vocab_size\n",
        "config[\"vit_kwargs\"][\"pretrained_model_name\"] = \"vit_tiny_patch16_224\"\n",
        "config[\"gpt_kwargs\"][\"ignore_index\"] = tokenizer.get_vocab()[tokenizer.pad_token]\n",
        "\n",
        "# Prepare data loaders for training and testing\n",
        "\n",
        "train_dl, test_dl = train_test_split(\n",
        "    train_config=train_config, model_config=config, data=data, tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model_config=config,\n",
        "    train_config=train_config,\n",
        "    dls=(train_dl, test_dl),\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Train the model and save metrics\n",
        "\n",
        "metrics = trainer.fit()\n",
        "metrics.to_csv(\"/content/training_data/checkpoints/metrics.csv\")\n",
        "\n",
        "# Plot training and test metrics\n",
        "trainer.plot_metrics()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b16a242f595c4900b32158f3a7601d3c",
            "9d39d2c6eaad4318aa58a8c599574423",
            "952591a5a5754a8c9024be44664e66c9",
            "45c56936ac804dacbb0929a98d0b55da",
            "08938eaef7e046a890deb289f937059a",
            "e38c5665e4ce4ac9bb18872b4023c2f2",
            "40cd38a2d2294487b760264ac55b5f96",
            "bd99cd0486fd47678430884a55872372",
            "17f671a9538146758cba9c5d11ccd94b",
            "6c66923f8a2947e38b3832b5c4a0ff34",
            "e54c32f3d6074b63afe8a1e297ad325a",
            "6ded22e93b604258a2b96e2a11646bba",
            "64926a61fca04e438f388a476b490345",
            "7d846111de834ef387dedf6a4d71f6d7",
            "521530748da34f61884b68ab26e8c282",
            "97f9f6a829e0418fa33d2516dfc3df78",
            "2d9d575622354a39b71c66ef3edf70c6",
            "ba0e2a91372241c39a69690e32ca0df0",
            "1f30605af0b64156b3986a9c6512d73f",
            "1f1b4c19218545baa7759049e45ec3e3",
            "489ec015d8394036906b48a888a261b5",
            "6adc1fa618624787ab5a2ab9942384ce",
            "b3f1a25e4f8446f2a09be2d556f5dc62",
            "f437d90c504d4a8ca7a879967faab33f",
            "cf1d6baa2f034737ad1f935744dd99fb",
            "0a15690a4bd24c1f8a701fe2f5f746fe",
            "c2012d7723bf4498906557d3a710478f",
            "c37c4885451f489490514f7564662194",
            "3be2af1c9c64461bbea2b342a89af209",
            "8550fa39b4c54e1a9c855d25e3ad6381",
            "68eb0f95264b40ad853500907636b766",
            "6a68b1d38e04440bafbd494418b5f49a",
            "db0417f070b44e4b8d0016e7f7a1047f",
            "dfb6fdd4257a4616b7be50cee096c3da",
            "7d5793e0c31c4666a8f7a216f071cf8e",
            "a1171e8c364d4f178468ec6e80904fc7",
            "bec0a0051ec04cb5bc7683c2e1cfe8a6",
            "0948ffca77784fddb523aee4cff3a344",
            "15dd8404550f43b284bf9792621b4174",
            "ea4b1c258ec1478589873ce52c025509",
            "ffff980c6dcd4c9bac8f83de98ad554a",
            "1b75d0dc63334228b97fc42db475df37",
            "e9053cfe0de44dd98f3d457c00667234",
            "9780bf95532f4333bf3e96a0b0dd5f30",
            "76be7eb355e4405593a5e00ba54d155c",
            "cad5df67fc0147d6876850be9e3a1791",
            "c3895efcceef49ecbe44906f03b231b0",
            "593f88b650eb48eb8af0dbe51ed66cff",
            "be99d5ca86f74470a7a684267e967cf7",
            "95817f3b074047d8a07fde98945c6bad",
            "c7a5bff435aa4c41b4c4cdfd5e72401f",
            "b93a5ea17b2a4f7e8021b78820fca13e",
            "4fce7ac0b0db42459c446a1f99aafced",
            "759a1c95166048cf9d03115115dc96de",
            "4764591e17194205b08c5baada26613a",
            "34571f245ed44416a0982fab9628fd98",
            "1fc19166924c4381b220c4a141cb99e1",
            "1395630b2ef74cd2827121be0e04e87c",
            "84be95abe875418cae409d14b61cf212",
            "ed43824f76dd4fdf8c7ce1564bf78911",
            "1c6384dd00bc411f83a1cd3e7a6ad37d",
            "9e441275178942a9bb6cedc1df39dcc4",
            "22d77f568500441d8783616d2359c0f5",
            "02fab976378e4931b4b9899a0c026cba",
            "0069bb6c193a4e7380fedb3c64656e3b",
            "df768885337142af8cd36f2e2cdb30d9"
          ]
        },
        "id": "4KomJqkfKeSy",
        "outputId": "34c275f8-f2fa-489f-f8fa-70f8b310b0c1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b16a242f595c4900b32158f3a7601d3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ded22e93b604258a2b96e2a11646bba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3f1a25e4f8446f2a09be2d556f5dc62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfb6fdd4257a4616b7be50cee096c3da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76be7eb355e4405593a5e00ba54d155c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/22.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34571f245ed44416a0982fab9628fd98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:timm.models._builder:Unexpected keys (norm.bias, norm.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
            "Processing Training Epoch 00:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 00: 100%|██████████| 282/282 [01:11<00:00,  3.96it/s, Train Loss=22.808, Train Perplexity=8045111808.0]\n",
            "Processing Eval Epoch 00: 100%|██████████| 32/32 [00:05<00:00,  5.98it/s, Test Loss=20.972, Test Perplexity=1282002560.0]\n",
            "<ipython-input-32-d9523d7365ce>:100: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.metrics = pd.concat([self.metrics, new_row], axis=0, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303   22.58557      2.347913e+15     6438551040.0     76.508206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 01:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 01: 100%|██████████| 282/282 [01:10<00:00,  3.98it/s, Train Loss=27.669, Train Perplexity=1039070593024.0]\n",
            "Processing Eval Epoch 01: 100%|██████████| 32/32 [00:05<00:00,  6.06it/s, Test Loss=17.312, Test Perplexity=33005832.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6438551040.0     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09      182198448.0    152.690202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 02:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 02: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=17.689, Train Perplexity=48095160.0]\n",
            "Processing Eval Epoch 02: 100%|██████████| 32/32 [00:05<00:00,  6.05it/s, Test Loss=14.936, Test Perplexity=3065947.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6438551040.0     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09      182198448.0    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08       19938834.0    234.444034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 03:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 03: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=19.023, Train Perplexity=182702336.0]\n",
            "Processing Eval Epoch 03: 100%|██████████| 32/32 [00:05<00:00,  6.12it/s, Test Loss=13.185, Test Perplexity=532120.6875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 04:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 04: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=12.246, Train Perplexity=208230.6875]\n",
            "Processing Eval Epoch 04: 100%|██████████| 32/32 [00:05<00:00,  6.00it/s, Test Loss=11.964, Test Perplexity=156944.109375]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 05:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 05: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=14.942, Train Perplexity=3084724.0]\n",
            "Processing Eval Epoch 05: 100%|██████████| 32/32 [00:05<00:00,  6.06it/s, Test Loss=11.079, Test Perplexity=64798.7421875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 06:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 06: 100%|██████████| 282/282 [01:16<00:00,  4.18it/s, Train Loss=13.786, Train Perplexity=971257.0625]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 06: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=13.786, Train Perplexity=971257.0625]\n",
            "Processing Eval Epoch 06: 100%|██████████| 32/32 [00:05<00:00,  6.01it/s, Test Loss=10.253, Test Perplexity=28356.650390625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 07:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 07: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=11.750, Train Perplexity=126738.2109375]\n",
            "Processing Eval Epoch 07: 100%|██████████| 32/32 [00:05<00:00,  6.14it/s, Test Loss=9.297, Test Perplexity=10900.54296875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 08:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 08: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=7.427, Train Perplexity=1680.5687255859375]\n",
            "Processing Eval Epoch 08: 100%|██████████| 32/32 [00:05<00:00,  6.02it/s, Test Loss=8.608, Test Perplexity=5475.9912109375]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 09:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 09: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=9.398, Train Perplexity=12060.291015625]\n",
            "Processing Eval Epoch 09: 100%|██████████| 32/32 [00:05<00:00,  6.11it/s, Test Loss=7.874, Test Perplexity=2628.049560546875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 10:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 10: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=5.358, Train Perplexity=212.31971740722656]\n",
            "Processing Eval Epoch 10: 100%|██████████| 32/32 [00:05<00:00,  6.02it/s, Test Loss=7.423, Test Perplexity=1674.201171875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 11:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 11: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=5.278, Train Perplexity=195.99563598632812]\n",
            "Processing Eval Epoch 11: 100%|██████████| 32/32 [00:05<00:00,  6.13it/s, Test Loss=6.830, Test Perplexity=924.9463500976562]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 12:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 12: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=11.047, Train Perplexity=62776.58984375]\n",
            "Processing Eval Epoch 12: 100%|██████████| 32/32 [00:05<00:00,  6.04it/s, Test Loss=6.357, Test Perplexity=576.2813720703125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 13:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 13: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=8.652, Train Perplexity=5719.10986328125]\n",
            "Processing Eval Epoch 13: 100%|██████████| 32/32 [00:05<00:00,  6.02it/s, Test Loss=6.202, Test Perplexity=493.70733642578125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 14:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 14: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=3.523, Train Perplexity=33.88056182861328]\n",
            "Processing Eval Epoch 14: 100%|██████████| 32/32 [00:05<00:00,  5.99it/s, Test Loss=5.932, Test Perplexity=376.9881591796875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 15:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 15: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=8.503, Train Perplexity=4929.60693359375]\n",
            "Processing Eval Epoch 15: 100%|██████████| 32/32 [00:05<00:00,  6.01it/s, Test Loss=5.793, Test Perplexity=328.1035461425781]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 16:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 16: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=5.984, Train Perplexity=396.9125671386719]\n",
            "Processing Eval Epoch 16: 100%|██████████| 32/32 [00:05<00:00,  6.08it/s, Test Loss=5.678, Test Perplexity=292.3964538574219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 17:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 17: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=7.421, Train Perplexity=1669.9332275390625]\n",
            "Processing Eval Epoch 17: 100%|██████████| 32/32 [00:05<00:00,  5.94it/s, Test Loss=5.551, Test Perplexity=257.6182556152344]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 18:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 18: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=8.314, Train Perplexity=4081.841064453125]\n",
            "Processing Eval Epoch 18: 100%|██████████| 32/32 [00:05<00:00,  6.06it/s, Test Loss=5.397, Test Perplexity=220.72683715820312]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 19:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 19: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=7.379, Train Perplexity=1602.6351318359375]\n",
            "Processing Eval Epoch 19: 100%|██████████| 32/32 [00:05<00:00,  5.99it/s, Test Loss=5.328, Test Perplexity=206.0595245361328]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 20:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 20: 100%|██████████| 282/282 [01:16<00:00,  4.20it/s, Train Loss=3.390, Train Perplexity=29.656110763549805]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 20: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=3.390, Train Perplexity=29.656110763549805]\n",
            "Processing Eval Epoch 20: 100%|██████████| 32/32 [00:05<00:00,  6.09it/s, Test Loss=5.232, Test Perplexity=187.1285400390625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 21:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 21: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=7.274, Train Perplexity=1442.523681640625]\n",
            "Processing Eval Epoch 21: 100%|██████████| 32/32 [00:05<00:00,  5.89it/s, Test Loss=5.326, Test Perplexity=205.576171875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 22:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 22: 100%|██████████| 282/282 [01:16<00:00,  3.67it/s, Train Loss=3.295, Train Perplexity=26.976940155029297]\n",
            "Processing Eval Epoch 22: 100%|██████████| 32/32 [00:05<00:00,  6.08it/s, Test Loss=5.054, Test Perplexity=156.6620635986328]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 23:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 23: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=5.496, Train Perplexity=243.62049865722656]\n",
            "Processing Eval Epoch 23: 100%|██████████| 32/32 [00:05<00:00,  5.85it/s, Test Loss=4.982, Test Perplexity=145.7528839111328]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 24:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 24: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=4.593, Train Perplexity=98.79317474365234]\n",
            "Processing Eval Epoch 24: 100%|██████████| 32/32 [00:05<00:00,  5.99it/s, Test Loss=4.844, Test Perplexity=126.99868774414062]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 25:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 25: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=3.622, Train Perplexity=37.40736770629883]\n",
            "Processing Eval Epoch 25: 100%|██████████| 32/32 [00:05<00:00,  5.98it/s, Test Loss=4.672, Test Perplexity=106.95361328125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 26:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 26: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=3.900, Train Perplexity=49.425838470458984]\n",
            "Processing Eval Epoch 26: 100%|██████████| 32/32 [00:05<00:00,  5.84it/s, Test Loss=4.595, Test Perplexity=98.99859619140625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 27:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 27: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=4.023, Train Perplexity=55.888458251953125]\n",
            "Processing Eval Epoch 27: 100%|██████████| 32/32 [00:05<00:00,  5.95it/s, Test Loss=4.631, Test Perplexity=102.62798309326172]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 28:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 28: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=3.261, Train Perplexity=26.072956085205078]\n",
            "Processing Eval Epoch 28: 100%|██████████| 32/32 [00:05<00:00,  5.97it/s, Test Loss=4.390, Test Perplexity=80.6097640991211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 29:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 29: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=4.728, Train Perplexity=113.06010437011719]\n",
            "Processing Eval Epoch 29: 100%|██████████| 32/32 [00:05<00:00,  6.12it/s, Test Loss=4.461, Test Perplexity=86.56462860107422]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 30:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 30: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=5.522, Train Perplexity=250.17747497558594]\n",
            "Processing Eval Epoch 30: 100%|██████████| 32/32 [00:05<00:00,  6.01it/s, Test Loss=4.309, Test Perplexity=74.38264465332031]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 31:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 31: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=2.953, Train Perplexity=19.17172622680664]\n",
            "Processing Eval Epoch 31: 100%|██████████| 32/32 [00:05<00:00,  5.98it/s, Test Loss=4.349, Test Perplexity=77.4119873046875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 32:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 32: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=4.224, Train Perplexity=68.30912780761719]\n",
            "Processing Eval Epoch 32: 100%|██████████| 32/32 [00:05<00:00,  5.83it/s, Test Loss=4.262, Test Perplexity=70.94734954833984]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n",
            "   33    3.567597   5.387438      3.543135e+01     2.186425e+02   2684.365606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 33:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 33: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=2.881, Train Perplexity=17.83112335205078]\n",
            "Processing Eval Epoch 33: 100%|██████████| 32/32 [00:05<00:00,  5.83it/s, Test Loss=4.024, Test Perplexity=55.90735626220703]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n",
            "   33    3.567597   5.387438      3.543135e+01     2.186425e+02   2684.365606\n",
            "   34    3.472264   5.292008      3.220959e+01     1.987421e+02   2766.284742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 34:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 34: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=3.995, Train Perplexity=54.34273910522461]\n",
            "Processing Eval Epoch 34: 100%|██████████| 32/32 [00:05<00:00,  5.78it/s, Test Loss=4.102, Test Perplexity=60.481693267822266]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n",
            "   33    3.567597   5.387438      3.543135e+01     2.186425e+02   2684.365606\n",
            "   34    3.472264   5.292008      3.220959e+01     1.987421e+02   2766.284742\n",
            "   35    3.369087   5.323175      2.905200e+01     2.050338e+02   2848.268849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 35:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 35: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=2.880, Train Perplexity=17.8170108795166]\n",
            "Processing Eval Epoch 35: 100%|██████████| 32/32 [00:05<00:00,  5.96it/s, Test Loss=4.010, Test Perplexity=55.163082122802734]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n",
            "   33    3.567597   5.387438      3.543135e+01     2.186425e+02   2684.365606\n",
            "   34    3.472264   5.292008      3.220959e+01     1.987421e+02   2766.284742\n",
            "   35    3.369087   5.323175      2.905200e+01     2.050338e+02   2848.268849\n",
            "   36    3.272057   5.287219      2.636553e+01     1.977926e+02   2930.057543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 36:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 36: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=4.827, Train Perplexity=124.8468017578125]\n",
            "Processing Eval Epoch 36: 100%|██████████| 32/32 [00:05<00:00,  5.98it/s, Test Loss=4.060, Test Perplexity=57.990455627441406]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n",
            "   33    3.567597   5.387438      3.543135e+01     2.186425e+02   2684.365606\n",
            "   34    3.472264   5.292008      3.220959e+01     1.987421e+02   2766.284742\n",
            "   35    3.369087   5.323175      2.905200e+01     2.050338e+02   2848.268849\n",
            "   36    3.272057   5.287219      2.636553e+01     1.977926e+02   2930.057543\n",
            "   37    3.196648   5.340657      2.445044e+01     2.086498e+02   3011.736029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 37:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 37: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=2.278, Train Perplexity=9.758587837219238]\n",
            "Processing Eval Epoch 37: 100%|██████████| 32/32 [00:05<00:00,  6.02it/s, Test Loss=4.077, Test Perplexity=58.98602294921875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n",
            "   33    3.567597   5.387438      3.543135e+01     2.186425e+02   2684.365606\n",
            "   34    3.472264   5.292008      3.220959e+01     1.987421e+02   2766.284742\n",
            "   35    3.369087   5.323175      2.905200e+01     2.050338e+02   2848.268849\n",
            "   36    3.272057   5.287219      2.636553e+01     1.977926e+02   2930.057543\n",
            "   37    3.196648   5.340657      2.445044e+01     2.086498e+02   3011.736029\n",
            "   38    3.091387   5.264614      2.200758e+01     1.933717e+02   3093.425438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 38:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 38: 100%|██████████| 282/282 [01:16<00:00,  3.69it/s, Train Loss=1.847, Train Perplexity=6.341773509979248]\n",
            "Processing Eval Epoch 38: 100%|██████████| 32/32 [00:05<00:00,  6.06it/s, Test Loss=4.016, Test Perplexity=55.4842643737793]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n",
            "   33    3.567597   5.387438      3.543135e+01     2.186425e+02   2684.365606\n",
            "   34    3.472264   5.292008      3.220959e+01     1.987421e+02   2766.284742\n",
            "   35    3.369087   5.323175      2.905200e+01     2.050338e+02   2848.268849\n",
            "   36    3.272057   5.287219      2.636553e+01     1.977926e+02   2930.057543\n",
            "   37    3.196648   5.340657      2.445044e+01     2.086498e+02   3011.736029\n",
            "   38    3.091387   5.264614      2.200758e+01     1.933717e+02   3093.425438\n",
            "   39    3.009066   5.293436      2.026846e+01     1.990260e+02   3175.069663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Training Epoch 39:   0%|          | 0/282 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Processing Training Epoch 39: 100%|██████████| 282/282 [01:16<00:00,  3.70it/s, Train Loss=4.138, Train Perplexity=62.696441650390625]\n",
            "Processing Eval Epoch 39: 100%|██████████| 32/32 [00:05<00:00,  5.92it/s, Test Loss=4.117, Test Perplexity=61.39387512207031]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  train_loss  test_loss  train_perplexity  test_perplexity  elapsed_time\n",
            "    1   35.392303  22.585570      2.347913e+15     6.438551e+09     76.508206\n",
            "    2   21.970902  19.020608      3.482100e+09     1.821984e+08    152.690202\n",
            "    3   18.691541  16.808181      1.311093e+08     1.993883e+07    234.444034\n",
            "    4   16.514637  15.000502      1.486674e+07     3.270661e+06    315.943347\n",
            "    5   14.798104  13.622375      2.671376e+06     8.243706e+05    397.552509\n",
            "    6   13.432748  12.416559      6.819747e+05     2.468557e+05    479.082246\n",
            "    7   12.244523  11.435749      2.078398e+05     9.257266e+04    560.659894\n",
            "    8   11.221639  10.567126      7.473013e+04     3.883691e+04    642.123221\n",
            "    9   10.340811   9.849517      3.097113e+04     1.894920e+04    723.631756\n",
            "   10    9.600934   9.250901      1.477858e+04     1.041395e+04    805.102346\n",
            "   11    8.915496   8.761445      7.446474e+03     6.383329e+03    886.680949\n",
            "   12    8.365556   8.306650      4.296499e+03     4.050721e+03    968.215465\n",
            "   13    7.869551   7.930048      2.616390e+03     2.779562e+03   1049.822656\n",
            "   14    7.431422   7.567947      1.688207e+03     1.935164e+03   1131.522494\n",
            "   15    7.012818   7.295815      1.110780e+03     1.474118e+03   1213.246195\n",
            "   16    6.683548   7.025170      7.991495e+02     1.124586e+03   1294.928835\n",
            "   17    6.353041   6.801323      5.742364e+02     8.990363e+02   1376.470856\n",
            "   18    6.078905   6.604322      4.365508e+02     7.382787e+02   1458.127910\n",
            "   19    5.810580   6.419342      3.338128e+02     6.135989e+02   1539.667991\n",
            "   20    5.568410   6.253956      2.620172e+02     5.200663e+02   1621.246411\n",
            "   21    5.335338   6.184795      2.075429e+02     4.853137e+02   1702.823568\n",
            "   22    5.149125   6.022623      1.722807e+02     4.126598e+02   1784.494271\n",
            "   23    4.947493   5.888834      1.408214e+02     3.609843e+02   1866.573289\n",
            "   24    4.771974   5.834839      1.181523e+02     3.420096e+02   1948.310292\n",
            "   25    4.607199   5.753245      1.002031e+02     3.152118e+02   2030.033359\n",
            "   26    4.436419   5.703040      8.447191e+01     2.997772e+02   2111.885341\n",
            "   27    4.302318   5.624366      7.387080e+01     2.770964e+02   2193.751869\n",
            "   28    4.161886   5.588018      6.419249e+01     2.672055e+02   2275.574014\n",
            "   29    4.031594   5.526530      5.635065e+01     2.512704e+02   2357.379969\n",
            "   30    3.911751   5.439324      4.998643e+01     2.302865e+02   2439.072995\n",
            "   31    3.795465   5.422359      4.449892e+01     2.264125e+02   2520.819820\n",
            "   32    3.678091   5.403940      3.957080e+01     2.222805e+02   2602.533404\n",
            "   33    3.567597   5.387438      3.543135e+01     2.186425e+02   2684.365606\n",
            "   34    3.472264   5.292008      3.220959e+01     1.987421e+02   2766.284742\n",
            "   35    3.369087   5.323175      2.905200e+01     2.050338e+02   2848.268849\n",
            "   36    3.272057   5.287219      2.636553e+01     1.977926e+02   2930.057543\n",
            "   37    3.196648   5.340657      2.445044e+01     2.086498e+02   3011.736029\n",
            "   38    3.091387   5.264614      2.200758e+01     1.933717e+02   3093.425438\n",
            "   39    3.009066   5.293436      2.026846e+01     1.990260e+02   3175.069663\n",
            "   40    2.940673   5.277787      1.892857e+01     1.959357e+02   3256.816200\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define model and pipeline parameters\n",
        "# checkpoint = \"/content/training_data/checkpoints/imagecraft.pt\"\n",
        "# dev = 'cpu'# torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# max_len = 40  # Maximum length of captions\n",
        "\n",
        "# # List of image paths to process\n",
        "# image_paths = [\n",
        "#     \"/content/training_data/dataset/flickr30k/images/1000092795.jpg\",\n",
        "#     \"/content/training_data/dataset/flickr30k/images/10002456.jpg\",\n",
        "#     \"/content/training_data/dataset/flickr30k/images/1000268201.jpg\",\n",
        "#     \"/content/training_data/dataset/flickr30k/images/1000344755.jpg\"\n",
        "# ]\n",
        "\n",
        "# imagecraft = ImageCraft(checkpoint, max_len, dev)\n",
        "# audio_buffer = imagecraft.generate(image_paths[0])\n",
        "# display(Audio(audio_buffer, rate=16000))"
      ],
      "metadata": {
        "id": "91bd0RZuUD6_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"/content/training_data/checkpoints/imagecraft.pt\"\n",
        "device = 'cpu'\n",
        "max_len = 40\n",
        "def imagecraft_interface(image_path):\n",
        "  \"\"\"Process image inputs and generate audio response.\"\"\"\n",
        "  imagecraft = ImageCraft(checkpoint, max_len, device)\n",
        "  audio_buffer = imagecraft.generate(image_path)\n",
        "  return audio_buffer\n",
        "\n",
        "# Define Gradio interface\n",
        "gradio_interface = gr.Interface(\n",
        "  fn=imagecraft_interface,\n",
        "  inputs=[\n",
        "    gr.Image(type=\"filepath\", label=\"Upload an image\")\n",
        "  ],\n",
        "  outputs=[\n",
        "    gr.Audio(label=\"Output Audio\")\n",
        "  ],\n",
        "  title=\"ImageCraft Assistant\",\n",
        "  description=\"Upload an image and get the speech responses.\",\n",
        "  allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "gradio_interface.launch(debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "KSszNhQuApaB",
        "outputId": "98fc1ee0-4da1-46eb-9c2c-dfb84692c54f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://174d9b023004ad4185.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://174d9b023004ad4185.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}